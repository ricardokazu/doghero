# doghero

This is the files for the challenge.

We used the site www.imovelweb.com.br for the scraping of the data.

For the scraping and crawling, it was used scrapy, in the DogHero/spiders folder, 'ImovelWebCrawl.py'.

The jupyter notebook 'Doghero.ipynb' has some notes and adaptation of the data for an easier analisys in the sql.

The data final is stored in the 'imovelweb-final.csv'.

The sql code is in 'Answersql.sql'.


The main information we will focus are: prices, location and the title of the item so we can identify it.

Other, features we will use for case of more especific searches.
