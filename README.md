# doghero

This is the files for the challenge.

We used the site www.imovelweb.com.br for the scraping of the data.

For the scraping and crawling, it was used scrapy, in the DogHero/spiders folder, 'ImovelWebCrawl.py'.
The jupyter notebook 'Doghero.ipynb' has some notes and adaptation of the data for an easier analisys in the sql.
The data final is stored in the 'imovelweb-final.csv'.
The sql code is in 'Answersql.sql'.


